{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/monokim/BERT/blob/master/Intent_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdw6bkfeAYn0"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l3MqPxeAYn3"
   },
   "source": [
    "Check If there is a GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "n1U_spRMAYn4",
    "outputId": "cfabfbf4-f3d4-45bb-8a18-26ce6be37dcd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "GeForce GTX 1060 will be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_name(0), 'will be used.')\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_dbmdz model will be used\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "dataset = 'german' # imdb, agnews, chatbot, ubuntu, german\n",
    "df = None\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "language_model = 'bert_dbmdz' # bert, albert, roberta, xlnet, bert_german, bert_multi, bert_dbmdz\n",
    "print(language_model + \" model will be used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxVfEMVkAYn8"
   },
   "source": [
    "### IMDB Movie review Dataset\n",
    "- 40,000 training samples\n",
    "- 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "TS9mqU28FZU8",
    "outputId": "5f55c4b5-cdd4-4747-9b7c-1e995fdf31df"
   },
   "outputs": [],
   "source": [
    "if dataset == 'imdb':\n",
    "    # Load the data set into a pandas dataframe\n",
    "    df = pd.read_csv(\"./Dataset/IMDB_Dataset.csv\", delimiter=',', header=None, names=['review', 'sentiment'])\n",
    "\n",
    "    full_labels = df.sentiment.values\n",
    "    full_labels = [1 if l == 'positive' else 0 for l in labels]\n",
    "    full_sentences = df.review.values\n",
    "    \n",
    "    # Shuffle\n",
    "    tmp = list(zip(full_sentences, full_labels))\n",
    "    random.shuffle(tmp)\n",
    "    full_sentences, full_labels = zip(*tmp)\n",
    "    \n",
    "    labels = full_labels[4000:]\n",
    "    sentences = full_sentences[4000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3v5awyN2bNTG"
   },
   "source": [
    "### AG NEWS Dataset\n",
    "- 120,000 training samples\n",
    "- 7,600 test samples\n",
    "- 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "jU3JutbJbNnU",
    "outputId": "a5a5c243-a322-4ac0-c10c-fce8a03fc674"
   },
   "outputs": [],
   "source": [
    "if dataset == 'agnews':\n",
    "    # Load the data set into a pandas dataframe\n",
    "    df = pd.read_csv(\"./Dataset/ag_news_train.csv\", delimiter=',', header=None, names=['category', \"head\", 'content'])\n",
    "\n",
    "    # Print number of sentences.\n",
    "    labels = df.category.values - 1\n",
    "    sentences = df.content.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot Corpus\n",
    "    - 206 samples\n",
    "    - 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'chatbot':\n",
    "    # Load the data set into a pandas dataframe\n",
    "    df = pd.read_json(\"./Dataset/ChatbotCorpus.json\")\n",
    "    text = df.sentences.values\n",
    "    full_sentences = []\n",
    "    full_labels = []\n",
    "    for t in text:\n",
    "        full_sentences.append(t['text'])\n",
    "        label = t['intent']\n",
    "        if label == 'FindConnection':\n",
    "            full_labels.append(0)\n",
    "        elif label == 'DepartureTime':\n",
    "            full_labels.append(1)\n",
    "    \n",
    "    # Shuffle\n",
    "    tmp = list(zip(full_sentences, full_labels))\n",
    "    random.shuffle(tmp)\n",
    "    full_sentences, full_labels = zip(*tmp)\n",
    "    \n",
    "    sentences = full_sentences[20:]\n",
    "    labels = full_labels[20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask Ubuntu corpus\n",
    "- 162 samples\n",
    "- 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'ubuntu':\n",
    "    # Load the data set into a pandas dataframe\n",
    "    df = pd.read_json(\"./Dataset/AskUbuntuCorpus.json\")\n",
    "    sentences = df.sentences.values\n",
    "    full_sentences = []\n",
    "    full_labels = []\n",
    "    for s in sentences:\n",
    "        full_sentences.append(s['text'])\n",
    "        label = s['intent']\n",
    "        if label == 'Make Update':\n",
    "            full_labels.append(0)\n",
    "        elif label == 'Setup Printer':\n",
    "            full_labels.append(1)\n",
    "        elif label == 'Shutdown Computer':\n",
    "            full_labels.append(2)\n",
    "        elif label == 'Software Recommendation':\n",
    "            full_labels.append(3)\n",
    "        elif label == 'None':\n",
    "            full_labels.append(4)\n",
    "    \n",
    "    # Shuffle\n",
    "    tmp = list(zip(full_sentences, full_labels))\n",
    "    random.shuffle(tmp)\n",
    "    full_sentences, full_labels = zip(*tmp)\n",
    "    \n",
    "    sentences = full_sentences[20:]\n",
    "    labels = full_labels[20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Dataset\n",
    "- 10kGNAD\n",
    "- 9,245 training sample\n",
    "- 9 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "if dataset == 'german':\n",
    "    # Load the data set into a pandas dataframe\n",
    "    with open(\"./Dataset/german_train.csv\",  \"r\", encoding='utf-8',) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';', quotechar='\\'')\n",
    "        for row in reader:\n",
    "            if row[0] == 'Web':\n",
    "                label = 0\n",
    "            elif row[0] == 'International':\n",
    "                label = 1\n",
    "            elif row[0] == 'Etat':\n",
    "                label = 2\n",
    "            elif row[0] == 'Wirtschaft':\n",
    "                label = 3\n",
    "            elif row[0] == 'Panorama':\n",
    "                label = 4\n",
    "            elif row[0] == 'Sport':\n",
    "                label = 5\n",
    "            elif row[0] == 'Wissenschaft':\n",
    "                label = 6\n",
    "            elif row[0] == 'Kultur':\n",
    "                label = 7\n",
    "            elif row[0] == 'Inland':\n",
    "                label = 8\n",
    "            \n",
    "            labels.append(label)\n",
    "            sentences.append(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size : 9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21-Jähriger fällt wohl bis Saisonende aus. Wien – Rapid muss wohl bis Saisonende auf Offensivspieler Thomas Murg verzichten. Der im Winter aus Ried gekommene 21-Jährige erlitt beim 0:4-Heimdebakel gegen Admira Wacker Mödling am Samstag einen Teilriss des Innenbandes im linken Knie, wie eine Magnetresonanz-Untersuchung am Donnerstag ergab. Murg erhielt eine Schiene, muss aber nicht operiert werden. Dennoch steht ihm eine mehrwöchige Pause bevor.', 'Erfundene Bilder zu Filmen, die als verloren gelten: \"The Forbidden Room\" von Guy Maddin und Evan Johnson ist ein surrealer Ritt durch die magischen Labyrinthe des frühen Kinos. Wien – Die Filmgeschichte ist ein Friedhof der Verlorenen. Unter den Begrabenen finden sich zahllose Filme, von denen nur noch mysteriös oder abenteuerlich klingende Namen kursieren; und solche, über die verstreut herumliegendes Sekundärmaterial Aufschluss erlaubt. Einer davon ist The Forbidden Room, ein Two-Reeler von 1913/14, den der arbeitswütige US-Regisseur Allan Dwan u. a. mit dem Horrordarsteller Lon Chaney gedreht hat. Ein passender Titel für einen Film, der als verschollen gilt. Verbote sind Einladungen zur Überschreitung. Einen ähnlichen Gedanken hatte wohl auch der kanadische Experimentalfilmemacher Guy Maddin, als er seinem Film von 2015 den gleichen Titel gab. Gemeinsam mit seinem Koregisseur Evan Johnson hat er vergessene, verschwundene Arbeiten der Film geschichte zum Ausgangspunkt einer Neuerfindung erkoren. Um historische Genauigkeit geht es ihnen dabei freilich nicht, erlaubt ist vielmehr alles, was die Fantasie so ausspuckt. Arg angespannte Szenen in einem U-Boot, dessen Besatzung tief im Ozean mit einer Art explosivem Gelee umhertaucht und Sauerstoff mit Pfannkuchen generiert. Oder die Erinnerungen eines Schnurrbarts, der sich auf die Oberlippe des Sohnes eines Toten heftet, um derart der Witwe Trost zu spenden. Letzteres die frei erfundene Handlung eines Mikio-Naruse-Films mit dem Titel The Strength of a Moustache. Immer neue Volten schlägt die Handlung, verläuft dabei kaum jemals linear, sondern gibt sich sprunghaft, surreal dem Unerwarteten hin, irgendwo zwischen Jules Verne, Jacques Tourneur, F. W. Murnau und dem von Maddin verehrten Modernisten Raymond Roussel. Der britische Guardian beschrieb das Ergebnis so: als würde man unter der Einwirkung von LSD durch ein Filmarchiv wandeln. Das Rausch- oder zumindest Traumähnliche teilt diese Arbeit Maddins mit seinen früheren, die kürzer dimensioniert waren. The Forbidden Room ist durch seine Dauer von mehr als zwei Stunden schon nahe an der Überdosis, soll heißen: Die Überforderung ist Programm. Maddin und Johnson geben sich mit keinen Häppchen zufrieden, sondern wollen ein immersives Seherlebnis ermöglichen, in einem mehr an Filmpionier Georges Méliès orientierten Sinne. Sie nehmen die fantastische Qualität des Kinos als seine eigentliche Realität wahr – eine wild Bilder pumpende, an unsere Psyche gekoppelte (und daher auch manchmal humorvoll kindliche) Maschine, wie sie schon in Maddins Kurzfilm The Heart of the World (2000) zur Geltung kam. Wer nach einem Zusammenhang sucht, findet ihn im Bekenntnis zur Abschweifung. Die Verbindung von einem Waldarbeiter (Roy Dupuis), der der Spur einer verschwundenen Frau folgt, zu einem (von Udo Kier verkörperten) Arzt mit einem Fetisch für Gesäße oder zu jenem seltsamen Reklamemenschen, der dem Zuschauer erklärt, wie man das perfekte Bad nimmt – sie liegt allenfalls in der Oberfläche, jener digital in der Postproduktion hergestellten Ästhetik des frühen Kinos, die The Forbidden Room wie ein Gespenst des analogen Zeitalters wachruft. Künstlich verwittert Die Farben der Laufbilder, die auf das eingeschränkte Zwei-Farben-Technicolor-Verfahren verweisen, sind künstlich heruntergestuft, als wäre das Filmmaterial der Verwitterung ausgesetzt gewesen; manche Doppelbelichtungen wirken so, als wären die Mate rialien ineinandergeschmolzen. Auch mit Zwischentiteln und dem weitgehenden Verzicht auf herkömmliche Dialoge schließen Maddin und Evan an den Stummfilm an, dessen stilistische Bandbreite sie in der Montage und szenischen Regie spielerisch betonen und ausagieren. Die Amnesie, heißt es in diesem visuell betörenden Film einmal, befällt jene Menschen, zu denen die Figuren aus der Ferne zurückkehren. Der Gedanke lässt sich auch auf die Bilder des Films anwenden: Er enthält die Fragmente eines Kinos, an das wir uns nicht mehr erinnern können, weil wir es für verloren hielten.', 'Der frischgekürte CEO Sundar Pichai setzt auf ein umgänglicheres Führungsteam. Die Atmosphäre im Silicon Valley ist rau. Da werden massenhaft Mitarbeiter der direkten Konkurrenz abgeworben, Löhne mit firmenübergreifenden Mauscheleien niedrig gehalten und Untergebene wegen leicht verfehlter Ziele vor die Tür gesetzt. Auch in der höchsten Firmenebene werden brutale Umgangsformen gepflegt: Die Wutausbrüche von Apple-Mitgründer Steve Jobs sind legendär, sein früherer Geschäftspartner Steve Wozniak hätte ihn zu Lebzeiten gerne als Arschloch beschimpft, traute sich aber nicht. Auch Google-Mitgründer Larry Page gilt als Choleriker, für den ein humaner Umgang mit Mitarbeitern nicht an erster Stelle steht. Doch die Zeiten des harten Management-Stils sind bei Google vorbei. Das belegen zahlreiche ehemalige Mitarbeiter und Geschäftspartner. Wie ein Ex-Manager gegenüber re:code pointiert verlautbart: Alle Arschlöcher sind jetzt weg. Verantwortlich dafür zeichnet sich Sundar Pichai, der nach Googles großer Umstrukturierung (Gründung des Dachunternehmens Alphabet) zum CEO des Suchmaschinisten wurde. In den wenigen Monaten als Google-Chef hat Pichai nun bereits einige Umstrukturierungen vorgenommen – und erhält dafür viel Lob aus der Branche. So wurde beispielsweise Hiroshi Lockheimer zum Android-Chef gemacht. Ehemalige Kollegen, etwa Motorola-Präsident Rick Osterloh, schwärmen von ihm als großartigen Typen, den man sehr gern hat. So soll Lockheimer dafür gesorgt haben, dass alle Smartphone-Hersteller, die auf Android setzen, gleichberechtigten Zugang zu Entwicklungen des Betriebssystems haben – auch, als Motorola noch zu Google gehörte. Ein anderes Beispiel ist Philipp Schindler, der Googles Werbegeschäft leiten soll. Medienpartner beschreiben ihn als kompromissbereit und umgänglich. Gelernt hat Schindler das in Europa, wo er Google jahrelang gegen Monopol-Vorwürfe aus Regierungskreisen verteidigen musste. Älterer Semester im Google-Umfeld befürchten laut re:code allerdings, dass ein softes Google wichtige Scharmützel verlieren wird. Doch die Zeit der ausgefahrenen Ellbogen ist vorerst vorbei.', 'Putin: \"Einigung, dass wir Menge auf Niveau von Jänner halten\". Moskau – Die russischen Ölproduzenten wollen nach den Worten von Präsident Wladimir Putin ihre Förderung in diesem Jahr einfrieren. Im Großen und Ganzen wurde eine Einigung erzielt, dass wir die Ölproduktion auf dem Niveau von Jänner halten werden, sagte Putin am Mittwoch in Moskau. Russland leidet wie andere Förderstaaten unter dem drastischen Einbruch der Ölpreise. Putin will die Preise durch eine begrenzte Förderung im In- und Ausland stabilisieren. Dazu hatte Russland jüngst mit Saudi-Arabien und anderen großen Förderländern über ein Einfrieren der Produktion auf dem Jänner-Niveau beraten.', 'Estland sieht den künftigen österreichischen Präsidenten auch als estnischen Staatsbürger. Wien/Tallinn/Pskow – Die Eltern des künftigen Bundespräsidenten waren 1941 aus dem von Sowjets besetzten Estland in das damalige Deutsche Reich geflohen, wo 1944 in Wien Sascha Van der Bellen zur Welt kam. Estnische Verwandte jubelten am Dienstag über dessen Wahlsieg, Freude herrscht auch unter Politikern des Landes. Interesse an Van der Bellen gibt es auch in der russischen Stadt Pskow, der Geburtsstadt seiner Eltern. Wir haben von ganzem Herzen und mit der ganzen Familie mitgefiebert, sagt Irina Steinberg, eine Cousine des künftigen Präsidenten. Der Sonntag sei für sie deshalb ein großer Stress gewesen, erzählt Steinberg im Telefonat mit der APA. Sein Sieg zeugt davon, dass die österreichische Intelligenzija, die denkenden Menschen, für Sascha gestimmt haben, so die studierte Philologin, die in einem Dorf im Süden Estlands lebt. Freudig wird der Wahlsieg des ehemaligen Grünen-Chefs auch von estnischen Politikern kommentiert. Die Wahl eines Präsidenten mit estnischen Wurzeln schafft günstige Bedingungen für eine engere Zusammenarbeit zwischen Estland und Österreich, erklärt der Vorsitzende des außenpolitischen Ausschusses im estnischen Parlament, Sven Mikser. Da Estland aber auch den Aufschwung europaskeptischer Kräfte mit Sorge beobachte, sei er froh, dass sich die Österreicher für Van der Bellen entscheiden haben, sagt der Vertreter der Sozialdemokratischen Partei Estlands gegenüber der APA. Das Wahlergebnis ist ein guter Grund, den Österreichern gleich doppelt zu gratulieren, betont der ehemalige Außenminister und nunmehrige liberale Europaparlamentsabgeordnete Urmas Paet. Van der Bellen sei für die jetzige Zeit eine sehr vernünftige Wahl, sie sei gut für Europa und Österreich, sagt Paet im Gespräch mit der APA. Für Estland und das estnische Volk spielt aber auch die Tatsache eine Rolle, dass Österreich einen estnischen Staatsbürger zum Präsidenten gewählt hat. Nach Auskunft des estnischen Außenministeriums gelten Kinder von Bewohnern des 1940 zerstörten unabhängigen Estland, die vor dem 16. Juni 1940 über die estnische Staatsbürgerschaft verfügten, automatisch als Staatsbürger des nunmehrigen Estland. Der APA vorliegende Dokumente des estnischen Staatsarchivs und des deutschen Bundesarchivs belegen, dass Alma und Alexander Van der Bellen senior, die Eltern des künftigen Präsidenten, damals im Besitz der estnischen Staatsbürgerschaft waren. Interesse am künftigen Präsidenten zeigt aber auch Pskow, das im Westen Russland an der heutigen estnischen Grenze liegt. Die ursprünglich aus Holland stammende Familie war hier im 19. Jahrhundert in den russischen Adelstand erhoben worden, insbesondere der ebenso gleichnamige Großvater von Alexander Van der Bellen hatte vor der Oktoberrevolution des Jahres 1917 eine tragende politische Funktion in der Region gespielt. Nach der bürgerlichen Februarrevolution von 1917 war dieser Vertreter eines russischen Liberalismus zum Kommissar der Übergangsregierung für das Gouvernement Pskow und somit zum lokalen Regierungschef ernannt worden. In einigen Lokalmedien finden sich Schlagzeilen, in denen vom Sieg des Nachfahren eines Aristokraten aus Pskow oder des Enkels des Pskower Gouverneurs die Rede ist, berichtet der Direktor des Archivs der Region Pskow, Waleri Kusmin. In diesem Archiv finden sich zahlreiche Akten zur Familie Van der Bellen, insbesondere zur politischen Tätigkeit der Vorfahren. Kusmin geht im Gespräch mit der APA davon aus, dass in der nächsten Zeit auch einige wissenschaftliche Publikationen über die Van der Bellens in Pskow erscheinen werden. Die Geschichte dieser Kleinaristokraten in Pskow ging nach der Machtübernahme der Bolschewiken zu Ende: 1919 floh die Familie, darunter die Großeltern und der Vater des künftigen Präsidenten, nach Estland. Als die Sowjets 1940 Estland eroberten, floh man erneut Richtung Westen. Van der Bellens Vater hatte zu diesem Zeitpunkt aufgrund seiner Herkunft und insbesondere als international tätiger Banker Repressionen des sowjetischen Geheimdiensts NKWD zu befürchten. Die Flucht ging zunächst nach Wien und Ende 1944, Anfang 1945 und somit rechtzeitig vor dem Eintreffen der Rote Armee in Ostösterreich weiter nach Tirol, wo Van der Bellen senior eine Existenz im Außenhandel aufbauen konnte und zudem ein künftiger Präsident heranwachsen sollte.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 0, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size : %d\" % len(labels))\n",
    "print(sentences[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJ2Sv3TkAYoG"
   },
   "source": [
    "# BERT Tokenizer\n",
    "\n",
    "### Tokenize each words and convert to token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "id": "uiMqEtkd3T7o",
    "outputId": "41a14a97-2ec1-46be-e7e4-8fa1e27529c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mingo\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (3.0.10)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (4.31.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (2020.2.20)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (0.0.38)\n",
      "Requirement already satisfied: requests in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: boto3 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (1.12.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from transformers) (1.16.2)\n",
      "Requirement already satisfied: six in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from requests->transformers) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from requests->transformers) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.14 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from boto3->transformers) (1.15.14)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from botocore<1.16.0,>=1.15.14->boto3->transformers) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\mingo\\anaconda3\\lib\\site-packages (from botocore<1.16.0,>=1.15.14->boto3->transformers) (0.14)\n"
     ]
    }
   ],
   "source": [
    "# Install transformers by using pip\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "f05b76c973f249519c510b7aade21510",
      "9250a549d7fd40ad93d2cdd12fb6f91f",
      "ad81993d700646b497f8fbcf2423fe15",
      "cb136730dc874ddb88ff884956c373c8",
      "af99d4addbca4e56970fb2a84d59ed74",
      "a4aa805f33c044f58c4d0dc5611364e1",
      "29ab35ebeb04449c97bfff988caaeb57",
      "f209950dc361472b88dca6a52006ea59"
     ]
    },
    "colab_type": "code",
    "id": "GrqOOw-LAYoH",
    "outputId": "0359a748-9e24-41e4-ac00-f3aa19c373c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :  21-Jähriger fällt wohl bis Saisonende aus. Wien – Rapid muss wohl bis Saisonende auf Offensivspieler Thomas Murg verzichten. Der im Winter aus Ried gekommene 21-Jährige erlitt beim 0:4-Heimdebakel gegen Admira Wacker Mödling am Samstag einen Teilriss des Innenbandes im linken Knie, wie eine Magnetresonanz-Untersuchung am Donnerstag ergab. Murg erhielt eine Schiene, muss aber nicht operiert werden. Dennoch steht ihm eine mehrwöchige Pause bevor.\n",
      "Tokenized :  ['21', '-', 'jahr', '##iger', 'fal', '##lt', 'wohl', 'bis', 'saison', '##ende', 'aus', '.', 'wie', '##n', '–', 'ra', '##pid', 'muss', 'wohl', 'bis', 'saison', '##ende', 'auf', 'offen', '##siv', '##spieler', 'th', '##omas', 'mu', '##rg', 'verzichten', '.', 'der', 'im', 'win', '##ter', 'aus', 'rie', '##d', 'gekommen', '##e', '21', '-', 'jahr', '##ige', 'erlitt', 'beim', '0', ':', '4', '-', 'heim', '##deb', '##akel', 'gegen', 'ad', '##mir', '##a', 'wa', '##cker', 'mod', '##ling', 'am', 'sam', '##stag', 'einen', 'teil', '##riss', 'des', 'innen', '##band', '##es', 'im', 'linken', 'kn', '##ie', ',', 'wie', 'eine', 'magnet', '##res', '##onanz', '-', 'unters', '##uch', '##ung', 'am', 'don', '##nerstag', 'ergab', '.', 'mu', '##rg', 'erhielt', 'eine', 'schien', '##e', ',', 'muss', 'aber', 'nicht', 'oper', '##iert', 'werden', '.', 'dennoch', 'steht', 'ihm', 'eine', 'mehr', '##wo', '##chi', '##ge', 'pa', '##use', 'bevor', '.']\n",
      "Token IDs :  [1735, 232, 9453, 693, 4682, 547, 2134, 378, 22522, 1071, 260, 566, 335, 30882, 809, 1919, 21326, 1092, 2134, 378, 22522, 1071, 216, 1872, 13640, 3680, 1773, 3283, 8130, 12438, 12698, 566, 125, 223, 16367, 162, 260, 10136, 30888, 3977, 30881, 1735, 232, 9453, 435, 16583, 916, 430, 853, 470, 232, 6005, 13155, 17171, 574, 3668, 11609, 30887, 12805, 2009, 11219, 3587, 339, 23156, 929, 397, 1418, 9744, 222, 12197, 4614, 115, 223, 7923, 6274, 110, 818, 335, 261, 27016, 3029, 18487, 232, 5033, 213, 132, 339, 17925, 2676, 12616, 566, 8130, 12438, 2326, 261, 13969, 30881, 818, 1092, 494, 255, 8732, 426, 338, 566, 6708, 1419, 1020, 261, 484, 1087, 15305, 124, 26668, 2284, 2784, 566]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import AlbertTokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import XLNetTokenizer\n",
    "\n",
    "# Load BERT Tokenizer\n",
    "if language_model == 'bert':\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "elif language_model == 'bert_german':\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased', do_lower_case=True)\n",
    "elif language_model == 'bert_multi':\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)\n",
    "elif language_model == 'bert_dbmdz':\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-cased', do_lower_case=True)\n",
    "    \n",
    "elif language_model == 'albert':\n",
    "    tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
    "elif language_model == 'roberta':\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "elif language_model == 'xlnet':\n",
    "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "    sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\n",
    "\n",
    "print('Original : ', sentences[0])\n",
    "print('Tokenized : ', tokenizer.tokenize(sentences[0]))\n",
    "print('Token IDs : ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sL40H1W1AYoK"
   },
   "source": [
    "### Sentence to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "u2m4kI1kAYoL",
    "outputId": "c8d3e81e-d7bb-403d-a537-b143c4ee0a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  21-Jähriger fällt wohl bis Saisonende aus. Wien – Rapid muss wohl bis Saisonende auf Offensivspieler Thomas Murg verzichten. Der im Winter aus Ried gekommene 21-Jährige erlitt beim 0:4-Heimdebakel gegen Admira Wacker Mödling am Samstag einen Teilriss des Innenbandes im linken Knie, wie eine Magnetresonanz-Untersuchung am Donnerstag ergab. Murg erhielt eine Schiene, muss aber nicht operiert werden. Dennoch steht ihm eine mehrwöchige Pause bevor.\n",
      "id:  [102, 1735, 232, 9453, 693, 4682, 547, 2134, 378, 22522, 1071, 260, 566, 335, 30882, 809, 1919, 21326, 1092, 2134, 378, 22522, 1071, 216, 1872, 13640, 3680, 1773, 3283, 8130, 12438, 12698, 566, 125, 223, 16367, 162, 260, 10136, 30888, 3977, 30881, 1735, 232, 9453, 435, 16583, 916, 430, 853, 470, 232, 6005, 13155, 17171, 574, 3668, 11609, 30887, 12805, 2009, 11219, 3587, 339, 23156, 929, 397, 1418, 9744, 222, 12197, 4614, 115, 223, 7923, 6274, 110, 818, 335, 261, 27016, 3029, 18487, 232, 5033, 213, 132, 339, 17925, 2676, 12616, 566, 8130, 12438, 2326, 261, 13969, 30881, 818, 1092, 494, 255, 8732, 426, 338, 566, 6708, 1419, 1020, 261, 484, 1087, 15305, 124, 26668, 2284, 2784, 566, 103]\n",
      "Max sentence length:  512\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "\n",
    "for s in sentences:\n",
    "    encoded_sentence = tokenizer.encode(s, max_length = 512, add_special_tokens=True)\n",
    "    input_ids.append(encoded_sentence)\n",
    "    \n",
    "print('original: ', sentences[0])\n",
    "print('id: ', input_ids[0])\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkHGEfJhAYoN"
   },
   "source": [
    "### Add padding and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvnwuYlZAYoO"
   },
   "outputs": [],
   "source": [
    "def add_padding_and_truncate(input_ids):\n",
    "    MAX_LEN = 64\n",
    "    for index, input_id in enumerate(input_ids):\n",
    "        for i in range(MAX_LEN - len(input_id)):\n",
    "          input_id.insert(0, 0)\n",
    "        if len(input_id) > MAX_LEN:\n",
    "          input_ids[index] = input_id[:MAX_LEN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dHoWz1rtAYoQ",
    "outputId": "24bbf0fa-3338-40ef-a254-705981638e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After max question length:  64\n"
     ]
    }
   ],
   "source": [
    "# Fit sentence's length to MAX_LEN\n",
    "add_padding_and_truncate(input_ids)\n",
    "\n",
    "print('After max question length: ', max([len(id) for id in input_ids]))\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "for id in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in id]\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ca1FnQVUAYoS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, labels, random_state=2020, test_size=0.1)\n",
    "train_masks, valid_masks, _, _ = train_test_split(attention_masks, labels, random_state=2020, test_size=0.1)\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "valid_inputs = torch.tensor(valid_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "valid_labels = torch.tensor(valid_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "valid_masks = torch.tensor(valid_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YeciXKeAYoX"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
    "valid_sampler = RandomSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyvHK7gbAYoZ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpfD-vUfAYoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels : 9\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "from transformers import AlbertForSequenceClassification, AlbertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetConfig\n",
    "\n",
    "num_label = max(labels) + 1\n",
    "print(\"Number of labels : %d\" % num_label)\n",
    "\n",
    "if language_model == 'bert':\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels = num_label, \n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "elif language_model == 'bert_german':\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-german-cased',\n",
    "        num_labels = num_label, \n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "elif language_model == 'bert_multi':\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-multilingual-cased',\n",
    "        num_labels = num_label, \n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "elif language_model == 'bert_dbmdz':\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-german-dbmdz-cased',\n",
    "        num_labels = num_label, \n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "    \n",
    "elif language_model == 'albert':\n",
    "    model = AlbertForSequenceClassification.from_pretrained(\n",
    "        'albert-base-v2',\n",
    "        num_labels = num_label,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "elif language_model == 'roberta':\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        'roberta-base',\n",
    "        num_labels = num_label,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "elif language_model == 'xlnet':\n",
    "    model = XLNetForSequenceClassification.from_pretrained(\n",
    "        'xlnet-base-cased',\n",
    "        num_labels = num_label,\n",
    "    )\n",
    "\n",
    "if device.type == 'cuda':\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOPm2ntbAYof"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlsy2adMAYoi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kJa6xacAYok"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1ErScfHqAYom",
    "outputId": "e88b3a6c-bfbe-4dea-a964-23759d4f2d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    260.    Elapsed: 0:00:29.\n",
      "  Batch    80  of    260.    Elapsed: 0:00:58.\n",
      "  Batch   120  of    260.    Elapsed: 0:01:27.\n",
      "  Batch   160  of    260.    Elapsed: 0:01:56.\n",
      "  Batch   200  of    260.    Elapsed: 0:02:25.\n",
      "  Batch   240  of    260.    Elapsed: 0:02:54.\n",
      "\n",
      "  Average training loss: 0.981\n",
      "  Training epoch took: 0:03:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.841\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    260.    Elapsed: 0:00:30.\n",
      "  Batch    80  of    260.    Elapsed: 0:01:00.\n",
      "  Batch   120  of    260.    Elapsed: 0:01:29.\n",
      "  Batch   160  of    260.    Elapsed: 0:01:59.\n",
      "  Batch   200  of    260.    Elapsed: 0:02:29.\n",
      "  Batch   240  of    260.    Elapsed: 0:02:59.\n",
      "\n",
      "  Average training loss: 0.473\n",
      "  Training epoch took: 0:03:14\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.860\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    260.    Elapsed: 0:00:31.\n",
      "  Batch    80  of    260.    Elapsed: 0:01:02.\n",
      "  Batch   120  of    260.    Elapsed: 0:01:33.\n",
      "  Batch   160  of    260.    Elapsed: 0:02:04.\n",
      "  Batch   200  of    260.    Elapsed: 0:02:36.\n",
      "  Batch   240  of    260.    Elapsed: 0:03:07.\n",
      "\n",
      "  Average training loss: 0.296\n",
      "  Training epoch took: 0:03:22\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.857\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    260.    Elapsed: 0:00:31.\n",
      "  Batch    80  of    260.    Elapsed: 0:01:02.\n",
      "  Batch   120  of    260.    Elapsed: 0:01:33.\n",
      "  Batch   160  of    260.    Elapsed: 0:02:04.\n",
      "  Batch   200  of    260.    Elapsed: 0:02:34.\n",
      "  Batch   240  of    260.    Elapsed: 0:03:05.\n",
      "\n",
      "  Average training loss: 0.204\n",
      "  Training epoch took: 0:03:20\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.864\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "Training complete!\n",
      "Training took: 0:13:31\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them\n",
    "loss_values = []\n",
    "\n",
    "t_total = time.time()\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear previously calculated gradients\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        # Returns a tuple\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 to prevent gradient explode\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate and store the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # For each batch of validation data\n",
    "    for batch in valid_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # No computing or storing gradients\n",
    "        with torch.no_grad():        \n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        \n",
    "    print(\"  Accuracy: {0:.3f}\".format(eval_accuracy / nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Training took: {:}\".format(format_time(time.time() - t_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAkvLl9pAYoo"
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Cmcj6mPBAYop",
    "outputId": "17a43dc1-1730-49f8-f6b6-52c2ac5eac88"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucVXW9//HXmwFUAi8JGXJX8Ryx8Dai6SkttYNWkHcQUn5qmGniJcu8nki8ZGlZpKGpmSji5SiZHlNLLRVlKLwgoYgK4yVHQ9FQAf38/vhuhmEYZjYwa9bee97Px2M/2Hut797zWW2b96zvWt/vVxGBmZkZQIe8CzAzs9LhUDAzs3oOBTMzq+dQMDOzeg4FMzOr51AwM7N6DgVrtyRVSXpPUt/WbGtWzuRxClYuJL3X4GUX4EPgo8Lr4yJicttXtf4knQ/0jogxeddi1jHvAsyKFRFdVzyX9BJwbETcv6b2kjpGxPK2qM2sUrj7yCqGpPMl3SzpJknvAqMlfU7SdElvS3pN0uWSOhXad5QUkvoXXt9Q2H+PpHclPSZpwNq2LezfX9Jzkt6R9AtJj0gasw7HtL2khwr1Py3pKw32fVXSnMLPr5V0SmH7pyTdXXjPvyQ9vK7/m1r741CwSnMgcCOwCXAzsBwYB3QH9gSGAsc18/4jgHOATwILgB+tbVtJnwKmAqcXfu6LwJC1PRBJnYG7gD8APYBTgJslbVNoci1wTER0AwYDDxW2nw7ML7zn04UazYriULBK89eI+H1EfBwR70fEjIh4PCKWR8R8YBKwVzPvvzUiaiJiGTAZ2HEd2n4VmBURdxb2XQa8uQ7HsifQGbgkIpYVusruAUYU9i8DBknqFhH/ioi/Ndi+JdA3IpZGxEOrfbLZGjgUrNIsbPhC0n9K+oOk1yUtBsaT/npfk9cbPF8CdF1Tw2babtmwjkh3c9QWUXtjWwILYtW7QV4GehWeHwgMAxZIelDSboXtFxXaPSDpBUmnr8PPtnbKoWCVpvHtdL8GngG2iYiNgXMBZVzDa0DvFS8kiZW/yNfGq0CfwvtX6Au8AlA4AxoGfIrUzTSlsH1xRJwSEf2BrwPfl9Tc2ZFZPYeCVbpuwDvAvyVtR/PXE1rLXcDOkr4mqSPpmkaPFt5TJWnDBo8NgEdJ10ROk9RJ0peAA4CpkjaSdISkjQtdVO9SuD238HO3LoTJO4XtHzX9Y81W5VCwSncacBTpl+avSRefMxUR/wQOBy4F3gK2Bv5OGlexJqOB9xs85kbEh8DXgOGkaxKXA0dExHOF9xwFvFzoFjsG+EZh+38AfwLeAx4Bfh4Rf221A7SK5sFrZhmTVEXqCjokIv6Sdz1mzfGZglkGJA2VtEmhG+gcUjfQEzmXZdYih4JZNv6LNFbgTdLYiK8XuoPMSpq7j8zMrJ7PFMzMrF7ZTYjXvXv36N+/f95lmJmVlZkzZ74ZES3dGl1+odC/f39qamryLsPMrKxIermYdpl1H0m6RtIbkp5Zw34VZpmcJ+kpSTtnVYuZmRUny2sK15HuuliT/YGBhcdY4IoMazEzsyJkFgoR8TDwr2aaDAeuj2Q6sKmknlnVY2ZmLcvz7qNerDqjZS3rNmmYmZm1kjxDoamZKpscNCFprKQaSTV1dXUZl2Vm1n7lGQq1QJ8Gr3uT5odZTURMiojqiKju0aPFO6pWM3ky9O8PHTqkfyeX5fLuZmbZyzMUpgFHFu5C2h14JyJea+0fMnkyjB0LL78MEenfsWMdDGZmTcnyltSbgMeA/ygsKn6MpG9J+lahyd2kuWHmAVcB386ijrPOgiVLVt22ZEnabmZmq8ps8FpEjGxhfwAnZPXzV1iwYO22m5m1ZxU/91Hfvmu33cysPav4UJgwAbp0WX37aae1fS1mZqWu4kNh1CiYNAn69QMJevaEDTaAG2+EpUvzrs7MrLRUfChACoaXXoKPP4ZXX4Xf/Q6mT4dTTsm7MjOz0tIuQqGxQw+F734XfvUruP76vKsxMysd7TIUAC68EPbeG447DmbNyrsaM7PS0G5DoWNHuPlm2HxzOOgg+FdzU/eZmbUT7TYUAD71Kbj1VqithdGj0zUHM7P2rF2HAsDuu8Pll8M998D48XlXY2aWr3YfCpCuKxx1FPzwh/CHP+RdjZlZfhwKpPELV1wBO+2UupFeeCHviszM8uFQKNhoI7jtthQQBx+8+iR6ZmbtgUOhgQED0kjnp55KXUrR5JI/ZmaVy6HQyNCh6drCDTekwW1mZu2JQ6EJZ50FX/0qnHwyPPpo3tWYmbUdh0ITOnRI8yP165emxHj99bwrMjNrGw6FNdh0U7j9dli0CA4/HJYty7siM7PsZRoKkoZKmitpnqQzmtjfT9IDkp6S9KCk3lnWs7YGD4arroKHH4bvfz/vaszMspflGs1VwERgf2AQMFLSoEbNfgJcHxGDgfHAhVnVs65GjYLvfAcuuyzNlWRmVsmyPFMYAsyLiPkRsRSYAgxv1GYQ8EDh+Z+b2F8SfvIT2HNPOOYYmD0772rMzLKTZSj0AhY2eF1b2NbQk8DBhecHAt0kbd74gySNlVQjqaauri6TYpvTuTNMnQrduqUZVd95p81LMDNrE1mGgprY1ng42HeBvST9HdgLeAVYvtqbIiZFRHVEVPfo0aP1Ky3CllumYHjhBRgzxjOqmlllyjIUaoE+DV73Bl5t2CAiXo2IgyJiJ+CswraS/Tv8859PXUl33AEXX5x3NWZmrS/LUJgBDJQ0QFJnYAQwrWEDSd0lrajhB8A1GdbTKsaNgxEj4Oyz4b778q7GzKx1ZRYKEbEcOBG4F5gDTI2I2ZLGSxpWaLY3MFfSc8AWwISs6mktElx9NQwaBCNHwssv512RmVnrUZTZrG/V1dVRU1OTdxk8/zxUV8PAgfDXv8KGG+ZdkZnZmkmaGRHVLbXziOZ1NHBgmgpj5sw0jsHMrBI4FNbDsGFp8ryrr04PM7Ny51BYTz/8IXz5y3DCCTBjRt7VmJmtH4fCeqqqSgvz9OyZVmx78828KzIzW3cOhVaw+eZpKc833kh3JH30Ud4VmZmtG4dCK9lll7RS2/33wznn5F2Nmdm6cSi0oqOPhrFj4cIL06hnM7Ny41BoZZdfDrvuCkceCXPn5l2NmdnacSi0sg02SNcXNtggzaj63nt5V2RmVjyHQgb69IEpU+Af/0hrMJTZoHEza8ccChnZZx+44II03fZll+VdjZlZcRwKGfre9+DAA9O/Dz2UdzVmZi1zKGRIguuug222gcMOg1deybsiM7PmORQytvHGcPvt8O9/w6GHwtKleVdkZrZmDoU2MGgQXHstPPYYnHpq3tWYma2ZQ6GNHHoonHYaTJyYptw2MytFmYaCpKGS5kqaJ+mMJvb3lfRnSX+X9JSkA7KsJ28XXQR7751GPc+alXc1ZmaryywUJFUBE4H9gUHASEmDGjU7m7RM506kNZx/lVU9paBjxzR+YfPN04yqixblXZGZ2aqyPFMYAsyLiPkRsRSYAgxv1CaAjQvPNwFezbCekrDFFnDrrbBwIYweDR9/nHdFZmYrZRkKvYCFDV7XFrY19D/AaEm1wN1AkwtbShorqUZSTV1dXRa1tqndd4ef/xzuvht+9KO8qzEzWynLUFAT2xpP+DASuC4iegMHAL+TtFpNETEpIqojorpHjx4ZlNr2vvWtNGneD3+YwsHMrBRkGQq1QJ8Gr3uzevfQMcBUgIh4DNgQ6J5hTSVDgiuvhB12gFGjYP78vCsyM8s2FGYAAyUNkNSZdCF5WqM2C4B9ACRtRwqF8u8fKtJGG6UZVaU0o+qSJXlXZGbtXWahEBHLgROBe4E5pLuMZksaL2lYodlpwDclPQncBIyJaF9zim61FUyeDE89lbqU2tfRm1mpUbn9Dq6uro6ampq8y2h148fDeeelwW3f/nbe1ZhZpZE0MyKqW2rnEc0l4uyz4StfgZNPTtNhmJnlwaFQIjp0SNNf9OkDhxwCr7+ed0Vm1h45FErIZpulGVUXLYLDD4dly/KuyMzaG4dCidlhB5g0CR5+GM5YbbYoM7NsORRK0OjRcOKJcOmlaTlPM7O24lAoUT/9KeyxBxx9NMyenXc1ZtZeOBRKVOfOcMst0LVrGtj2zjt5V2Rm7YFDoYRtuWXqPnrhBRgzxgPbzCx7DoUS94UvwE9+AnfcARdfnHc1ZlbpHAplYNy4dIvqWWfB/ffnXY2ZVTKHQhmQ4OqrYbvtYMQIWLAg74rMrFI5FMpE165pYNuyZWkpzw8+yLsiM6tEDoUysu22cP31UFMDJ52UdzVmVokcCmVm+HA480y46ir4zW/yrsbMKo1DoQyNHw/77QcnnJDOGszMWotDoQxVVcGNN8IWW6TrC2++mXdFZlYpHAplqnv3tJTnP/8JI0fCRx/lXZGZVYJMQ0HSUElzJc2TtNqcn5IukzSr8HhO0ttZ1lNpqqvTSm333w/nnJN3NWZWCTpm9cGSqoCJwH5ALTBD0rSIeHZFm4g4pUH77wA7ZVVPpTrmGHj8cbjwQhgyBL7+9bwrMrNyluWZwhBgXkTMj4ilwBRgeDPtRwI3ZVhPxbr88nTWcNRR8NxzeVdjZuUsy1DoBSxs8Lq2sG01kvoBA4A/rWH/WEk1kmrq6upavdByt+GG6fpC585pRtX33su7IjMrV1mGgprYtqZ5PkcAt0ZEk5dLI2JSRFRHRHWPHj1arcBK0rcvTJkCc+bAscd6RlUzWzdZhkIt0KfB697Aq2toOwJ3Ha23ffaBCRPg5pvhZz/LuxozK0dZhsIMYKCkAZI6k37xT2vcSNJ/AJsBj2VYS7vx/e/DgQfC6aendZ7NzNZGZqEQEcuBE4F7gTnA1IiYLWm8pGENmo4EpkS4w6M1SHDddbD11nDYYfDqms7NzMyaoHL7XVxdXR01ntuhRc8+m25RHTwYHnwwXYQ2s/ZL0syIqG6pnUc0V6hBg+Caa+Cxx+C00/KuxszKhUOhgh12GJx6Kvzyl3DDDXlXY2blwKFQ4S6+GPbaC8aOhSefzLsaMyt1DoUK17FjukV1s83SwLZFi/KuyMxKmUOhHdhiC7j1Vli4EEaPho8/zrsiMytVDoV24nOfSwPa7r4bzj8/72rMrFQ5FNqR44+HI4+E//kfuOeevKsxs1LkUGhHJLjiijR24YgjYP78vCsys1LjUGhnunSB229Pzw86CJYsybceMystDoV2aKutYPJkeOqp1KVUZoPazSxDDoV26oAD4Lzz4Prr4cor867GzEqFQ6EdO+ecFA7jxqXpMMzMHArtWIcOafqLPn3gkEPgn//MuyIzy1tRoSBpa0kbFJ7vLekkSZtmW5q1hc02SxeeFy2Cww+H5cvzrsjM8lTsmcJtwEeStgF+Q1pP+cbMqrI2tcMOMGkSPPQQnHFG3tWYWZ6KDYWPC4vmHAj8LCJOAXpmV5a1tdGj4YQT4Kc/halT867GzPJSbCgskzQSOAq4q7CtU0tvkjRU0lxJ8yQ1+TeopMMkPStptiSffeTo0kvTdBhHH50W6TGz9qfYUPh/wOeACRHxoqQBQLMz9EuqAiYC+wODgJGSBjVqMxD4AbBnRGwPnLyW9Vsr6twZbrkFPvGJtM7z4sV5V2Rmba2oUIiIZyPipIi4SdJmQLeIuKiFtw0B5kXE/IhYCkwBhjdq801gYkQsKvycN9ayfmtlvXql7qMXXoAxYzywzay9KfbuowclbSzpk8CTwLWSLm3hbb2AhQ1e1xa2NbQtsK2kRyRNlzR0DT9/rKQaSTV1dXXFlGzrYa+94JJL4H//F37847yrMbO2VGz30SYRsRg4CLg2InYB9m3hPWpiW+O/OzsCA4G9gZHA1U3d6hoRkyKiOiKqe/ToUWTJtj5OPjndonrmmfDAA3lXY2ZtpdhQ6CipJ3AYKy80t6QW6NPgdW/g1Sba3BkRyyLiRWAuKSQsZxJcfTVstx2MGAELFuRdkZm1hWJDYTxwL/BCRMyQtBXwfAvvmQEMlDRAUmdgBDCtUZs7gC8CSOpO6k7yhM4lomvXNLDtww/TiOcPPsi7IjPLWrEXmm+JiMERcXzh9fyIOLiF9ywHTiSFyRxgakTMljRe0rBCs3uBtyQ9C/wZOD0i3lrXg7HWt+22adK8GTPgpJPyrsbMsqYo4vYSSb2BXwB7kq4L/BUYFxG12Za3uurq6qipqWnrH9vunXkmXHhh6lI65pi8qzGztSVpZkRUt9Su2O6ja0ldP1uS7iD6fWGbtRM/+hHsu28a9exMNqtcxYZCj4i4NiKWFx7XAb4NqB2pqoKbboIttoCDD4Y338y7IjPLQrGh8Kak0ZKqCo/RgPv+25nu3eG22+D119Mazx99lHdFZtbaig2Fo0m3o74OvAYcQpr6wtqZ6mqYOBHuuw/OPTfvasystRV799GCiBgWET0i4lMR8XXSQDZrh449Nj0uuADuvDPvasysNa3PymuntloVVnZ+8Yt01nDkkfDcc3lXY2atZX1CoalpLKyd2HBDuPVW6NQJDjoI3nsv74rMrDWsTyh4/sx2rl8/mDIF5sxJ3UmeUdWs/DUbCpLelbS4ice7pDEL1s7tuy+cfz7cfDP8/Od5V2Nm66tjczsjoltbFWLl64wz4Ikn4LvfhV12gc9/Pu+KzGxdrU/3kRmQZlS97jrYems49FB4tfFcuGZWNhwK1io22STNqPreeykYli7NuyIzWxcOBWs1228P11wDjz6aupLMrPw4FKxVHXYYnHpqGsdwww15V2Nma8uhYK3uoovgC1+AsWPhySfzrsbM1oZDwVpdp04wdSpstlka2LZoUd4VmVmxHAqWiS22gFtugYUL01QYH3+cd0VmVoxMQ0HSUElzJc2TdEYT+8dIqpM0q/A4Nst6rG3tsQdcdhncdRdMmJB3NWZWjGYHr60PSVXARGA/oBaYIWlaRDzbqOnNEXFiVnVYvr79bXj8cTjvvDSB3v77512RmTUnyzOFIcC8iJgfEUuBKcDwDH+elSAJrrwSBg+GUaNg/vy8KzKz5mQZCr2AhQ1e1xa2NXawpKck3SqpT1MfJGmspBpJNXV1dVnUahnq0iWt2BaRlvJ8//28KzKzNckyFJqaWrvxPJq/B/pHxGDgfuC3TX1QREyKiOqIqO7Rw0tDl6Ott4bJk2HWLDj+eM+oalaqsgyFWqDhX/69gVVmxYmItyLiw8LLq4BdMqzHcnbAAenawm9/m7qUzKz0ZBkKM4CBkgZI6gyMAKY1bCCpZ4OXw4A5GdZjJeDcc1M4jBsH06fnXY2ZNZZZKETEcuBE4F7SL/upETFb0nhJwwrNTpI0W9KTwEnAmKzqsdLQoQP87nfQu3e6E6lPn7Stf//UvWRm+VKUWedudXV11NTU5F2GracLLoCzzlp1W5cuMGlSukvJzFqXpJkRUd1SO49otlxMmrT6tiVLVg8KM2tbDgXLxYIFTW9/+WXPlWSWJ4eC5aJv3zXv690bTjgBnnuu7eoxs8ShYLmYMCFdQ2ioS5d0reHww+Hqq+E//xOGDYM//9njGszaikPBcjFqVLqu0K9fmgqjX7/0+gc/SKu3LVgA55yTblv90pdg553T+IYPP2z5s81s3fnuIytpH3yQblW97DKYPRs+/ek0yd63vgUe3G5WPN99ZBVhww3hmGPg6afhj3+EnXZKA+D69k0ruz3beM5dM1svDgUrCxLstx/cfXcKgqOOSoPgtt8ehg6Fe+/1dQez1uBQsLKz3XZp7qSFC+H88+Gpp1IwfOYz6QK1Z2E1W3cOBStb3bunwW4vvQTXXw8bbADf/GbqWjr3XHj99bwrNCs/DgUre507wze+ATNnpttX99gjnUH06wdjxsCTT+ZdoVn5cChYxZBg773hzjth7tx0IfrWW2HHHdNtrb//PXz8cd5VmpU2h4JVpIED4Re/SNcdLr4Ynn8+DYTbbjv41a/g3//Ou0Kz0uRQsIq22Wbwve+ltaFvugk23TRNodGnD5xxBtTW5l2hWWlxKFi70KkTjBiRRkg/8gjssw9ccgkMGJBGV3s8pFniULB2RUoXom+5BebNg+98J11r2HVX+Pzn4fbb4aOP8q7SLD+ZhoKkoZLmSpon6Yxm2h0iKSS1OATbrLUMGACXXpq6kC67DF55BQ4+OF2P+NnPYPHivCs0a3uZhYKkKmAisD8wCBgpaVAT7bqRluJ8PKtazJqz8cZw8snpYvRtt0GvXnDKKem6w6mnpnEQZu1FlmcKQ4B5ETE/IpYCU4DhTbT7EfBj4IMMazFrUVUVHHQQ/OUv8MQT8JWvpDuYtt4aDj0UHn3UU2lY5csyFHoBCxu8ri1sqydpJ6BPRNzV3AdJGiupRlJNXV1d61dq1siuu8KNN8KLL8Lpp8P998Oee8Luu8OUKbBsWd4VmmUjy1BQE9vq/86S1AG4DDitpQ+KiEkRUR0R1T08X7K1od694aKL0nWHiRPTUqEjR6azh0sugbffzrtCs9aVZSjUAn0avO4NvNrgdTfgM8CDkl4Cdgem+WKzlaJPfCKt4/CPf8C0abDNNmn8Q+/e6Q6mefPyrtCsdWQZCjOAgZIGSOoMjACmrdgZEe9ERPeI6B8R/YHpwLCI8B3jVrI6dICvfQ3+9Cf4+9/hkEPg17+GbbeF4cPhwQd93cHKW2ahEBHLgROBe4E5wNSImC1pvKRhWf1cs7ay445w3XXw8stpttZHHoEvfhF22SWt9bB0ad4Vmq09L8dp1krefx9uuCGNcXj2WejZM02pcdxxaZpvszx5OU6zNrbRRmk9h2eegf/7Pxg8GM4+O413OO44mDMn7wrNWuZQMGtlEvz3f6dgeOYZGD0afvtbGDQIDjgA7rvP1x2sdDkUzDK0/fZw1VVpCu/x4+Fvf4MvfzmdRfzmN/CBh2xaiXEomLWBHj3gnHPSRenrrkt3MR17bFo69Lzz4J//zLtCs8ShYNaGNtgAjjoKZs2CBx6A3XZLZxB9+8LRR8PTT+ddobV3DgWzHEgrlwidOzedNdx8c+pW2ndf+MMfvHSo5cOhYJazbbdNU2gsXAgXXphGTX/1q+nC9BVXeOlQa1sOBbMS8clPpiVCX3wRJk+Gbt3S1Bp9+sCZZ6b1Hsyy5lAwKzGdOsERR6Tpu//ylzRK+uKLoX//dHvrzJl5V2iVzKFgVqIk+K//Sgv/PP98Gh19551QXQ1f+ALccYeXDrXW51AwKwNbbZWmz6ithZ/+FBYsgAMPTNcjLr8c3n037wqtUjgUzMrIJpukJULnzYNbboEttoBx49J1h+9+N42DMFsfDgWzMtSxY5q2+9FHYfp0GDo0nUlsvTUcdhg89ljeFVq5ciiYlbnddktLhM6fn84i/vhH2GMP+NznYOpUWL487wqtnDgUzCpE377w4x+n6w6XXw51dXD44ens4Sc/8dKhVhyHglmF6do1LRE6d266Q2nAADj99HTdYdw4eOGFvCu0UpZpKEgaKmmupHmSzmhi/7ckPS1plqS/ShqUZT1m7UlV1colQmfOTHcrXXEFDByYnj/8sKfwttVlFgqSqoCJwP7AIGBkE7/0b4yIz0bEjsCPgUuzqsesPdt5Z7j+enjpJfjBD1Ig7LVXGvNwww1eOtRWyvJMYQgwLyLmR8RSYAowvGGDiFjc4OUnAP/dYpahLbeECRPSPEtXXglLlsA3vpG6mC64AH796zRyukOH9O/kyXlXbG2tY4af3QtY2OB1LbBb40aSTgBOBToDX8qwHjMr6NIlLRH6zW/CvffCZZfBWWet2ubll2Hs2PR81Ki2r9HykeWZgprYttqZQERMjIitge8DZzf5QdJYSTWSaurq6lq5TLP2q0MH2H//dBtrz56r71+yBE48MXU3vf9+29dnbS/LUKgF+jR43Rt4tZn2U4CvN7UjIiZFRHVEVPfo0aMVSzSzFV5/ventb7+drj9ssgnsvjucdhrcfrtXi6tUWYbCDGCgpAGSOgMjgGkNG0ga2ODlV4DnM6zHzJrRt2/T23v3hmnT0sC4Tp3S2g8HHwyf/jRss01aSW7SJJg92wsDVYLMrilExHJJJwL3AlXANRExW9J4oCYipgEnStoXWAYsAo7Kqh4za96ECekawpIlK7d16QIXXQRf+1p6AHz4Ifztb/DII+lxzz3pziaAzTZLI6n33DM9dt01fYaVD0WZ3ahcXV0dNTU1eZdhVpEmT04XnBcsSGcOEya0fJE5Ik3QtyIkHnkE5sxJ+zp2TLfDrgiJPfdMZxjW9iTNjIjqFts5FMystb31VpqUb0VIzJgBH3yQ9m211aohMWhQuuBt2XIomFnJWLp01S6nRx6BN95I+zbddNUupyFD3OWUBYeCmZWsiDQHU8OQePbZtK9jR9hpp1XPJpq6XdbWjkPBzMrKv/61apfTE0+s7HIaMGDVkNh+e3c5rS2HgpmVtaVL4e9/X/VsYsXYiE02Wb3L6ROfyLfeUudQMLOKEpEWEmoYErNnp31VVat3OW25Zb71lhqHgplVvEWLVu9yWjEdR//+q3c5VVXlWm6uHApm1u4sW7Z6l9OK6Ts23njVLqfddmtfXU4OBTNr9yLgxRdX73KKSGcNO+646tlEr155V5wdh4KZWRPefnvVLqfHH1/Z5dS376oh8dnPVk6Xk0PBzKwIy5bBrFmrnk289lra161bmhl2RUjsvntaA7scORTMzNZBRFpgqGFIPP102t6hA+yww6pnE336tPyZpcChYGbWSt55B6ZPX7XL6d//Tvv69Fk1JAYPLs0uJ4eCmVlGli+HJ59c9WzilVfSvq5dV+9y6tYt33rBoWBm1mYi0nTjDUPiqadWdjkNHrzq2cSaFjTKkkPBzCxHixev2uU0ffrKLqfevVfvcuqY2ZJniUPBzKyELF+ezh4ank3U1qZ9XbumwXQNu5w23njle9dl8aPGSiIUJA0Ffk5ajvPqiLio0f5TgWOB5UAdcHREvNzcZzoUzKxSNNXl9PHHqcvps59NAQFw7bUrx1JAWm9i0qS1C4bcQ0FSFfAcsB9QC8wARkbEsw3afBF4PCKWSDoe2DsiDm/ucx0KZlapFi9OdzY17HJ6772m2/brBy+9VPxnFxsKWfZiDQHWSg91AAAGkklEQVTmRcT8QkFTgOFAfShExJ8btJ8OjM6wHjOzkrbxxrDffukBqcupc+d0wbqxBQuyqSHLZSp6AQsbvK4tbFuTY4B7mtohaaykGkk1dXV1rViimVnp6thxzXcqZXUHU5ahoCa2NdlXJWk0UA1c0tT+iJgUEdURUd2jR49WLNHMrLRNmLD6mtVduqTtWcgyFGqBhgPAewOvNm4kaV/gLGBYRHyYYT1mZmVn1Kh0UblfP5DSv2t7kXltZHlNYQYwUNIA4BVgBHBEwwaSdgJ+DQyNiDcyrMXMrGyNGpVdCDSW2ZlCRCwHTgTuBeYAUyNitqTxkoYVml0CdAVukTRL0rSs6jEzs5ZlOoYuIu4G7m607dwGz/fN8uebmdnayfKagpmZlRmHgpmZ1XMomJlZvbKbEE9SHdDs/EjN6A682Yrl5MnHUnoq5TjAx1Kq1udY+kVEiwO9yi4U1oekmmLm/igHPpbSUynHAT6WUtUWx+LuIzMzq+dQMDOzeu0tFCblXUAr8rGUnko5DvCxlKrMj6VdXVMwM7PmtbczBTMza4ZDwczM6lVkKEgaKmmupHmSzmhi/waSbi7sf1xS/7avsjhFHMsYSXWFCQVnSTo2jzpbIukaSW9IemYN+yXp8sJxPiVp57ausVhFHMvekt5p8J2c21S7vEnqI+nPkuZImi1pXBNtyuJ7KfJYyuV72VDSE5KeLBzLD5tok93vsIioqAdQBbwAbAV0Bp4EBjVq823gysLzEcDNede9HscyBvhl3rUWcSxfAHYGnlnD/gNIK+8J2J20dnfuda/jsewN3JV3nUUcR09g58LzbqQ11Rv/91UW30uRx1Iu34uAroXnnYDHgd0btcnsd1glninUrw0dEUuBFWtDNzQc+G3h+a3APpKaWikub8UcS1mIiIeBfzXTZDhwfSTTgU0l9Wyb6tZOEcdSFiLitYj4W+H5u6Qp7hsvmVsW30uRx1IWCv9bv1d42anwaHxHUGa/wyoxFIpZG7q+TaR1H94BNm+T6tZOsetcH1w4tb9VUp8m9peDtV3Tu9R9rnD6f4+k7fMupiWF7oedSH+VNlR230szxwJl8r1IqpI0C3gDuC8i1vi9tPbvsEoMhWLWhi56/eicFVPn74H+ETEYuJ+Vfz2Um3L5TorxN9I8MzsAvwDuyLmeZknqCtwGnBwRixvvbuItJfu9tHAsZfO9RMRHEbEjaRnjIZI+06hJZt9LJYZCMWtD17eR1BHYhNLsDmjxWCLirVi5tvVVwC5tVFtrK2pN73IQEYtXnP5HWmiqk6TuOZfVJEmdSL9EJ0fE7U00KZvvpaVjKafvZYWIeBt4EBjaaFdmv8MqMRTq14aW1Jl0EabxMp/TgKMKzw8B/hSFKzYlpsVjadS/O4zUl1qOpgFHFu522R14JyJey7uodSHp0yv6dyUNIf3/7K18q1pdocbfAHMi4tI1NCuL76WYYymj76WHpE0LzzcC9gX+0ahZZr/DMl2OMw8RsVzSirWhq4BrorA2NFATEdNI//H8TtI8UrqOyK/iNSvyWE5SWvN6OelYxuRWcDMk3US6+6O7pFrgPNIFNCLiStKyrQcA84AlwP/Lp9KWFXEshwDHS1oOvA+MKNE/OvYEvgE8Xei/BjgT6Atl970Ucyzl8r30BH4rqYoUXFMj4q62+h3maS7MzKxeJXYfmZnZOnIomJlZPYeCmZnVcyiYmVk9h4KZmdVzKJg1IumjBjNpzlITs9Oux2f3X9PsqmaloOLGKZi1gvcLUwyYtTs+UzArkqSXJF1cmOv+CUnbFLb3k/RAYVLCByT1LWzfQtL/FiZge1LSHoWPqpJ0VWGu/D8WRq2alQSHgtnqNmrUfXR4g32LI2II8EvgZ4VtvyRNLz0YmAxcXth+OfBQYQK2nYHZhe0DgYkRsT3wNnBwxsdjVjSPaDZrRNJ7EdG1ie0vAV+KiPmFyddej4jNJb0J9IyIZYXtr0VEd0l1QO8GExaumNb5vogYWHj9faBTRJyf/ZGZtcxnCmZrJ9bwfE1tmvJhg+cf4Wt7VkIcCmZr5/AG/z5WeP4oKyckGwX8tfD8AeB4qF80ZeO2KtJsXfkvFLPVbdRgpk2A/4uIFbelbiDpcdIfVCML204CrpF0OlDHyplExwGTJB1DOiM4Hii5aafNGvI1BbMiFa4pVEfEm3nXYpYVdx+ZmVk9nymYmVk9nymYmVk9h4KZmdVzKJiZWT2HgpmZ1XMomJlZvf8PbpUCYzSQPwQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_values, 'b-o')\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vyWFO7rAYor"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "if dataset == 'imdb':\n",
    "    sentences = df.review.values[1:4000]\n",
    "    labels = df.sentiment.values[1:4000]\n",
    "    \n",
    "elif dataset == 'agnews':\n",
    "    df = pd.read_csv(\"./Dataset/ag_news_test.csv\", delimiter=',', header=None, names=['category', \"head\", 'content'])\n",
    "    sentences = df.content.values\n",
    "    labels = df.category.values - 1\n",
    "\n",
    "elif dataset == 'chatbot':\n",
    "    sentences = full_sentences[:20]\n",
    "    labels = full_labels[:20]\n",
    "\n",
    "elif dataset == 'ubuntu':\n",
    "    sentences = full_sentences[:20]\n",
    "    labels = full_labels[:20]\n",
    "\n",
    "elif dataset == 'german':\n",
    "    with open(\"./Dataset/german_test.csv\",  \"r\", encoding='utf-8',) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';', quotechar='\\'')\n",
    "        for row in reader:\n",
    "            if row[0] == 'Web':\n",
    "                label = 0\n",
    "            elif row[0] == 'International':\n",
    "                label = 1\n",
    "            elif row[0] == 'Etat':\n",
    "                label = 2\n",
    "            elif row[0] == 'Wirtschaft':\n",
    "                label = 3\n",
    "            elif row[0] == 'Panorama':\n",
    "                label = 4\n",
    "            elif row[0] == 'Sport':\n",
    "                label = 5\n",
    "            elif row[0] == 'Wissenschaft':\n",
    "                label = 6\n",
    "            elif row[0] == 'Kultur':\n",
    "                label = 7\n",
    "            elif row[0] == 'Inland':\n",
    "                label = 8\n",
    "\n",
    "            labels.append(label)\n",
    "            sentences.append(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "ZPBuLiXxAYos",
    "outputId": "e7ea777d-05ca-4add-f399-a1ed96585c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size : 1028\n",
      "Accuracy: 0.850\n",
      "Validation took: 0:00:19\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Test size : %d\" % len(labels))\n",
    "t0 = time.time() \n",
    "\n",
    "if language_model == 'xlnet':\n",
    "    sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\n",
    "\n",
    "input_ids = []\n",
    "\n",
    "for s in sentences:\n",
    "    encoded_sentence = tokenizer.encode(s, max_length = 512, add_special_tokens=True)\n",
    "    input_ids.append(encoded_sentence)\n",
    "        \n",
    "add_padding_and_truncate(input_ids)\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "for id in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in id]\n",
    "    attention_masks.append(att_mask)\n",
    "    \n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "eval_accuracy = 0\n",
    "eval_steps = 0\n",
    "for batch in prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    eval_steps += 1\n",
    "\n",
    "print(\"Accuracy: {0:.3f}\".format(eval_accuracy / eval_steps))\n",
    "print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Intent_Classification_BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "29ab35ebeb04449c97bfff988caaeb57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9250a549d7fd40ad93d2cdd12fb6f91f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4aa805f33c044f58c4d0dc5611364e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad81993d700646b497f8fbcf2423fe15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4aa805f33c044f58c4d0dc5611364e1",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af99d4addbca4e56970fb2a84d59ed74",
      "value": 231508
     }
    },
    "af99d4addbca4e56970fb2a84d59ed74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cb136730dc874ddb88ff884956c373c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f209950dc361472b88dca6a52006ea59",
      "placeholder": "​",
      "style": "IPY_MODEL_29ab35ebeb04449c97bfff988caaeb57",
      "value": " 232k/232k [00:00&lt;00:00, 990kB/s]"
     }
    },
    "f05b76c973f249519c510b7aade21510": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad81993d700646b497f8fbcf2423fe15",
       "IPY_MODEL_cb136730dc874ddb88ff884956c373c8"
      ],
      "layout": "IPY_MODEL_9250a549d7fd40ad93d2cdd12fb6f91f"
     }
    },
    "f209950dc361472b88dca6a52006ea59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
